{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a36c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff24dc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_transform = transforms.Compose([\n",
    "                                       transforms.Resize((200,200)),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       ])\n",
    "\n",
    "path = os.path.join(os.getcwd(), \"#4 Garbage_classification\")\n",
    "folders = list()\n",
    "test_dataset = []\n",
    "train_dataset = []\n",
    "validation_dataset = []\n",
    "\n",
    "for folder in os.listdir(path):  folders.append(folder)\n",
    "\n",
    "for folder_idx in range(len(folders)):\n",
    "    fpath = os.path.join(path, folders[folder_idx])\n",
    "    pics = list()\n",
    "    \n",
    "    for pic in os.listdir(fpath): pics.append(pic)\n",
    "    num1 = int(len(pics)*0.8)\n",
    "    num2 = int(len(pics)*0.1)\n",
    "    \n",
    "    for img in pics:\n",
    "        im = Image.open(os.path.join(fpath, img))\n",
    "        im = custom_transform(im)\n",
    "        if img in pics[:num1]: train_dataset.append([im, folder_idx])\n",
    "        elif img in pics[num1:num1+num2]: validation_dataset.append([im, folder_idx])\n",
    "        else: test_dataset.append([im, folder_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16a71b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(dataset = test_dataset, batch_size = 8, shuffle = False)\n",
    "train_loader = DataLoader(dataset = train_dataset, batch_size = 24, shuffle = True)\n",
    "validation_loader = DataLoader(dataset = validation_dataset, batch_size = 8, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831b58ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alexnet model\n",
    "import torch.nn\n",
    "class Alexnet(torch.nn.Module):\n",
    "    def __init__(self, in_channels = 3, num_classes = 12):\n",
    "        super(Alexnet, self).__init__()\n",
    "\n",
    "        self.block1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=in_channels,\n",
    "                            out_channels=64,\n",
    "                            kernel_size=(11, 11),\n",
    "                            stride=(4, 4),\n",
    "                            padding=2),\n",
    "            torch.nn.ReLU(inplace = True),\n",
    "            torch.nn.MaxPool2d(kernel_size=(3, 3),\n",
    "                                stride=(2, 2))\n",
    "        )\n",
    "        self.block2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=64,\n",
    "                            out_channels=192,\n",
    "                            kernel_size=(5, 5),\n",
    "                            stride=(1, 1),\n",
    "                            padding=2),\n",
    "            torch.nn.ReLU(inplace = True),\n",
    "            torch.nn.MaxPool2d(kernel_size=(3, 3),\n",
    "                                stride=(2, 2))\n",
    "        )\n",
    "        self.block3 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=192,\n",
    "                            out_channels=384,\n",
    "                            kernel_size=(3, 3),\n",
    "                            stride=(1, 1),\n",
    "                            padding=1),\n",
    "            torch.nn.ReLU(inplace = True),\n",
    "            torch.nn.Conv2d(in_channels=384,\n",
    "                            out_channels=256,\n",
    "                            kernel_size=(3, 3),\n",
    "                            stride=(1, 1),\n",
    "                            padding=1),\n",
    "            torch.nn.ReLU(inplace = True),\n",
    "            torch.nn.Conv2d(in_channels=256,\n",
    "                            out_channels=256,\n",
    "                            kernel_size=(3, 3),\n",
    "                            stride=(1, 1),\n",
    "                            padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=(3, 3),\n",
    "                                stride=(2, 2))\n",
    "        )\n",
    "\n",
    "        self.avgpool = torch.nn.AdaptiveAvgPool2d((6,6))\n",
    "\n",
    "        self.classifier = torch.nn.Sequential(\n",
    "            torch.nn.Dropout(0.5),\n",
    "            torch.nn.Linear(256*6*6,4096),\n",
    "            torch.nn.ReLU(inplace = True),\n",
    "            torch.nn.Dropout(0.5),\n",
    "            torch.nn.Linear(4096,4096),\n",
    "            torch.nn.ReLU(inplace = True),\n",
    "            torch.nn.Linear(4096,num_classes),    \n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1e8ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Googlenet model\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class Inception_block(nn.Module):\n",
    "    def __init__(self, in_channels, out_1x1, red_3x3, out_3x3, red_5x5, out_5x5, out_1x1pool):\n",
    "        super(Inception_block, self).__init__()\n",
    "\n",
    "        self.branch1 = conv_block(in_channels, out_1x1, kernel_size = 1)\n",
    "        self.branch2 = nn.Sequential(\n",
    "            conv_block(in_channels, red_3x3, kernel_size = 1),\n",
    "            conv_block(red_3x3, out_3x3, kernel_size = 3,padding = 1)\n",
    "        )\n",
    "        self.branch3 = nn.Sequential(\n",
    "            conv_block(in_channels, red_5x5, kernel_size = 1),\n",
    "            conv_block(red_5x5, out_5x5, kernel_size = 5, padding=2)\n",
    "        )\n",
    "        self.branch4 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            conv_block(in_channels, out_1x1pool, kernel_size = 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return torch.cat([self.branch1(x), self.branch2(x), self.branch3(x), self.branch4(x)], 1)\n",
    "\n",
    "\n",
    "class conv_block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, **kwargs):\n",
    "        super(conv_block,self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, **kwargs)\n",
    "        self.batchnorm = nn.BatchNorm2d(out_channels)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.relu(self.batchnorm(self.conv(x)))\n",
    "    \n",
    "\n",
    "class GoogleNet(nn.Module):\n",
    "    def __init__(self,in_channels = 3, num_classes = 12):\n",
    "        super(GoogleNet, self).__init__()\n",
    "\n",
    "        self.conv1 = conv_block(in_channels=in_channels, out_channels=64, kernel_size = (7,7),\n",
    "                                stride = (2,2), padding = (3,3))\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = conv_block(64, 192, kernel_size = 3, stride = 1, padding =1)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # In order: in_channels, out_1x1, red_3x3, out_3x3, red_5x5, out_5x5, out_1x1pool\n",
    "\n",
    "        self.inception3a = Inception_block(192,64,96,128,16,32,32)\n",
    "        self.inception3b = Inception_block(256,128,128,192,32,96,64)\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.inception4a = Inception_block(480,192,96,208,16,48,64)\n",
    "        self.inception4b = Inception_block(512,160,112,224,24,64,64)\n",
    "        self.inception4c = Inception_block(512,128,128,256,24,64,64)\n",
    "        self.inception4d = Inception_block(512,112,144,288,32,64,64)\n",
    "        self.inception4e = Inception_block(528,256,160,320,32,128,128)\n",
    "        self.maxpool4 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.inception5a = Inception_block(832,256,160,320,32,128,128)\n",
    "        self.inception5b = Inception_block(832,384,192,384,48,128,128)\n",
    "\n",
    "        self.avgpool = nn.AvgPool2d(kernel_size=7, stride=1)\n",
    "        self.dropout = nn.Dropout(p = 0.4)\n",
    "        self.fc1 = nn.Linear(1024,1000)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool2(x)\n",
    "\n",
    "        x = self.inception3a(x)\n",
    "        x = self.inception3b(x)\n",
    "        x = self.maxpool3(x)\n",
    "        \n",
    "        x = self.inception4a(x) \n",
    "        x = self.inception4b(x)\n",
    "        x = self.inception4c(x)\n",
    "        x = self.inception4d(x)\n",
    "        x = self.inception4e(x)\n",
    "        x = self.maxpool4(x)\n",
    "\n",
    "        x = self.inception5a(x)\n",
    "        x = self.inception5b(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a34bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # VGG13 + BN\n",
    "\n",
    "import torch.nn\n",
    "class VGG13(torch.nn.Module):\n",
    "    def __init__(self, num_classes = 12):\n",
    "        super(VGG13, self).__init__()\n",
    "\n",
    "        self.block_1 = torch.nn.Sequential(\n",
    "                    torch.nn.Conv2d(in_channels=3,\n",
    "                                    out_channels=64,\n",
    "                                    kernel_size=(3, 3),\n",
    "                                    stride=(1, 1),\n",
    "                                    padding=1),\n",
    "                    torch.nn.BatchNorm2d(64),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.Conv2d(in_channels=64,\n",
    "                                    out_channels=64,\n",
    "                                    kernel_size=(3, 3),\n",
    "                                    stride=(1, 1),\n",
    "                                    padding=1),\n",
    "                    torch.nn.BatchNorm2d(64),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.MaxPool2d(kernel_size=(2, 2),\n",
    "                                       stride=(2, 2))\n",
    "        )\n",
    "        self.block_2 = torch.nn.Sequential(\n",
    "                    torch.nn.Conv2d(in_channels=64,\n",
    "                                    out_channels=128,\n",
    "                                    kernel_size=(3, 3),\n",
    "                                    stride=(1, 1),\n",
    "                                    padding=1),\n",
    "                    torch.nn.BatchNorm2d(128),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.Conv2d(in_channels=128,\n",
    "                                    out_channels=128,\n",
    "                                    kernel_size=(3, 3),\n",
    "                                    stride=(1, 1),\n",
    "                                    padding=1),\n",
    "                    torch.nn.BatchNorm2d(128),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.MaxPool2d(kernel_size=(2, 2),\n",
    "                                       stride=(2, 2))\n",
    "        )\n",
    "\n",
    "        self.block_3 = torch.nn.Sequential(        \n",
    "                    torch.nn.Conv2d(in_channels=128,\n",
    "                                    out_channels=256,\n",
    "                                    kernel_size=(3, 3),\n",
    "                                    stride=(1, 1),\n",
    "                                    padding=1),\n",
    "                    torch.nn.BatchNorm2d(256),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.Conv2d(in_channels=256,\n",
    "                                    out_channels=256,\n",
    "                                    kernel_size=(3, 3),\n",
    "                                    stride=(1, 1),\n",
    "                                    padding=1),\n",
    "                    torch.nn.BatchNorm2d(256),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.MaxPool2d(kernel_size=(2, 2),\n",
    "                                       stride=(2, 2))\n",
    "        )\n",
    "        self.block_4 = torch.nn.Sequential(   \n",
    "                    torch.nn.Conv2d(in_channels=256,\n",
    "                                    out_channels=512,\n",
    "                                    kernel_size=(3, 3),\n",
    "                                    stride=(1, 1),\n",
    "                                    padding=1),\n",
    "                    torch.nn.BatchNorm2d(512),\n",
    "                    torch.nn.ReLU(),        \n",
    "                    torch.nn.Conv2d(in_channels=512,\n",
    "                                    out_channels=512,\n",
    "                                    kernel_size=(3, 3),\n",
    "                                    stride=(1, 1),\n",
    "                                    padding=1),\n",
    "                    torch.nn.BatchNorm2d(512),\n",
    "                    torch.nn.ReLU(),      \n",
    "                    torch.nn.MaxPool2d(kernel_size=(2, 2),\n",
    "                                       stride=(2, 2))\n",
    "        )\n",
    "        self.block_5 = torch.nn.Sequential(\n",
    "                    torch.nn.Conv2d(in_channels=512,\n",
    "                                    out_channels=512,\n",
    "                                    kernel_size=(3, 3),\n",
    "                                    stride=(1, 1),\n",
    "                                    padding=1),\n",
    "                    torch.nn.BatchNorm2d(512),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.Conv2d(in_channels=512,\n",
    "                                    out_channels=512,\n",
    "                                    kernel_size=(3, 3),\n",
    "                                    stride=(1, 1),\n",
    "                                    padding=1),\n",
    "                    torch.nn.BatchNorm2d(512),\n",
    "                    torch.nn.ReLU(),    \n",
    "                    torch.nn.MaxPool2d(kernel_size=(2, 2),\n",
    "                                       stride=(2, 2))\n",
    "        )\n",
    "        height, width = 6, 6 ## you may want to change that depending on the input image size\n",
    "        self.classifier = torch.nn.Sequential(\n",
    "                torch.nn.Linear(512*height*width, 4096),\n",
    "                torch.nn.ReLU(True),\n",
    "                torch.nn.Dropout(p=0.5),\n",
    "                torch.nn.Linear(4096, 1000),\n",
    "                torch.nn.ReLU(True),\n",
    "                torch.nn.Dropout(p=0.5),\n",
    "                torch.nn.Linear(1000, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block_1(x)\n",
    "        x = self.block_2(x)\n",
    "        x = self.block_3(x)\n",
    "        x = self.block_4(x)\n",
    "        x = self.block_5(x)\n",
    "        x = x.view(x.size(0), -1) # flatten\n",
    "        x = self.classifier(x)\n",
    "        #probas = F.softmax(logits, dim=1)\n",
    "        return x  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc2939c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resnet50 model\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, identity_downsample = None, stride = 1):\n",
    "        super(block, self).__init__()\n",
    "        self.expansion = 4\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv3 = nn.Conv2d(out_channels, out_channels*self.expansion, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels*self.expansion)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.identity_downsample = identity_downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        if self.identity_downsample is not None:\n",
    "            identity = self.identity_downsample(identity)\n",
    "        \n",
    "        x = identity + x\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, img_channels, num_classes):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(img_channels, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # Resnet layers\n",
    "\n",
    "        self.layer1 = self.make_layer(block, layers[0], out_channels=64, stride=1)\n",
    "        self.layer2 = self.make_layer(block, layers[1], out_channels=128, stride=2)\n",
    "        self.layer3 = self.make_layer(block, layers[2], out_channels=256, stride=2)\n",
    "        self.layer4 = self.make_layer(block, layers[3], out_channels=512, stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(512*4, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    def make_layer(self, block, num_residual_blocks, out_channels, stride):\n",
    "        identity_downsampling = None\n",
    "        layers = []\n",
    "\n",
    "        if stride !=1 or self.in_channels != out_channels*4:\n",
    "            identity_downsampling = nn.Sequential(nn.Conv2d(self.in_channels, out_channels*4, kernel_size=1, stride=stride),\n",
    "                                                nn.BatchNorm2d(out_channels*4))\n",
    "        \n",
    "        layers.append(block(self.in_channels, out_channels, identity_downsampling, stride))\n",
    "        self.in_channels = out_channels * 4\n",
    "\n",
    "        for i in range(num_residual_blocks-1):\n",
    "            layers.append(block(self.in_channels, out_channels))\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "def Resnet50(img_channels = 3, num_classes =12):\n",
    "    return ResNet(block, [3,4,6,3], img_channels, num_classes)\n",
    "\n",
    "def Resnet101(img_channels = 3, num_classes =12):\n",
    "    return ResNet(block, [3,4,23,3], img_channels, num_classes)\n",
    "\n",
    "def Resnet152(img_channels = 3, num_classes =12):\n",
    "    return ResNet(block, [3,8,36,3], img_channels, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48659860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inception ResnetV1 \n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class conv_block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        super(conv_block,self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.batchnorm = nn.BatchNorm2d(out_channels)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.relu(self.batchnorm(self.conv(x)))\n",
    "\n",
    "class block_A(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels) -> None:\n",
    "        super(block_A, self).__init__()\n",
    "        self.branch1 = nn.Sequential(\n",
    "            conv_block(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=1, padding=0),\n",
    "            conv_block(in_channels=out_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        )\n",
    "\n",
    "        self.branch2 = nn.Sequential(\n",
    "            conv_block(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=1, padding=0),\n",
    "            conv_block(in_channels=out_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1),\n",
    "            conv_block(in_channels=out_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        )\n",
    "\n",
    "        self.conv1 = conv_block(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=1, padding=0) \n",
    "        self.conv2 = nn.Conv2d(in_channels=out_channels*3, out_channels=in_channels, kernel_size=1, stride=1, padding=0) \n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        x = torch.cat([self.branch1(x), self.branch2(x), self.conv1(x)], 1)\n",
    "        x = self.conv2(x)\n",
    "        x = identity + x\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class reduction_A(nn.Module):\n",
    "    def __init__(self, in_channels, k, l, m, n):\n",
    "        super(reduction_A, self).__init__()\n",
    "\n",
    "        self.branch1 = nn.Sequential(\n",
    "            conv_block(in_channels=in_channels, out_channels=k, kernel_size=1, stride=1, padding=0),\n",
    "            conv_block(in_channels=k, out_channels=l, kernel_size=3, stride=1, padding=1),\n",
    "            conv_block(in_channels=l, out_channels=m, kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        self.conv3 = conv_block(in_channels=in_channels, out_channels=n, kernel_size=3, stride=2, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        #self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.cat([self.branch1(x), self.conv3(x), self.pool(x)], 1)\n",
    "        #x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class block_B(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels) -> None:\n",
    "        super(block_B, self).__init__()\n",
    "\n",
    "        self.branch = nn.Sequential(\n",
    "            conv_block(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=1, padding=0),\n",
    "            nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=(1,7), stride=1, padding=(0,3)),\n",
    "            nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=(7,1), stride=1, padding=(3,0)),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.conv1 = conv_block(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.conv2 = nn.Conv2d(in_channels=out_channels*2, out_channels=in_channels, kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        x = torch.cat([self.branch(x), self.conv1(x)], 1)\n",
    "        x = self.conv2(x)\n",
    "        x = identity + x\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class reduction_B(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, out_channels2):\n",
    "        super(reduction_B, self).__init__()\n",
    "\n",
    "        self.branch1 = nn.Sequential(\n",
    "            conv_block(in_channels, out_channels, 1,1,0),\n",
    "            conv_block(out_channels,out_channels,3,1,1),\n",
    "            conv_block(out_channels, out_channels, 3,2,1)\n",
    "        )\n",
    "\n",
    "        self.branch2 = nn.Sequential(\n",
    "            conv_block(in_channels, out_channels,1,1,0),\n",
    "            conv_block(out_channels, out_channels,3,2,1)\n",
    "        )\n",
    "\n",
    "        self.branch3 = nn.Sequential(\n",
    "            conv_block(in_channels, out_channels,1,1,0),\n",
    "            conv_block(out_channels, out_channels2,3,2,1)\n",
    "        )\n",
    "\n",
    "        self.pool = nn.MaxPool2d(3,2,1)\n",
    "        #self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = torch.cat([self.branch1(x), self.branch2(x), self.branch3(x), self.pool(x)], 1)\n",
    "        #x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class block_C(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels) -> None:\n",
    "        super(block_C, self).__init__()\n",
    "\n",
    "        self.branch = nn.Sequential(\n",
    "            conv_block(in_channels, out_channels, 1,1,0),\n",
    "            nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=(1,3), stride=1, padding=(0,1)),\n",
    "            nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=(3,1), stride=1, padding=(1,0)),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.conv1 = conv_block(in_channels, out_channels,1,1,0)\n",
    "        self.conv2 = nn.Conv2d(out_channels*2, in_channels,1,1,0)\n",
    "        #self.downsample = nn.Conv2d(in_channels, out_channels2,1,1,0)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        identity = x#self.downsample(x)\n",
    "        x = torch.cat([self.branch(x), self.conv1(x)],1)\n",
    "        x = self.conv2(x)\n",
    "        x = identity + x\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class InceptionResnet(nn.Module):\n",
    "    def __init__(self, in_channels=3, num_classes=12):\n",
    "        super(InceptionResnet, self).__init__()\n",
    "        # stem begins\n",
    "        self.stem = nn.Sequential(\n",
    "            conv_block(in_channels=in_channels, out_channels=32, kernel_size=3, stride=2, padding=1),\n",
    "            conv_block(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "            conv_block(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            conv_block(in_channels=64, out_channels=80, kernel_size=1, stride=1, padding=1),\n",
    "            conv_block(in_channels=80, out_channels=192, kernel_size=3, stride=1, padding=1),\n",
    "            conv_block(in_channels=192, out_channels=256, kernel_size=3, stride=2, padding=1),\n",
    "        )\n",
    "        # stem ends\n",
    "\n",
    "        self.inceptionresnetA1 = block_A(256, 32)\n",
    "        self.inceptionresnetA2 = block_A(256, 32)\n",
    "        self.inceptionresnetA3 = block_A(256, 32)\n",
    "        self.inceptionresnetA4 = block_A(256, 32)\n",
    "        self.inceptionresnetA5 = block_A(256, 32)\n",
    "\n",
    "        self.reductiona = reduction_A(256, 192,192,256,384)\n",
    "\n",
    "        self.inceptionresnetB1 = block_B(896, 128)\n",
    "        self.inceptionresnetB2 = block_B(896, 128)\n",
    "        self.inceptionresnetB3 = block_B(896, 128)\n",
    "        self.inceptionresnetB4 = block_B(896, 128)\n",
    "        self.inceptionresnetB5 = block_B(896, 128)\n",
    "        self.inceptionresnetB6 = block_B(896, 128)\n",
    "        self.inceptionresnetB7 = block_B(896, 128)\n",
    "        self.inceptionresnetB8 = block_B(896, 128)\n",
    "        self.inceptionresnetB9 = block_B(896, 128)\n",
    "        self.inceptionresnetB10 = block_B(896, 128)\n",
    "\n",
    "        self.reductionb = reduction_B(896, 256, 384)\n",
    "\n",
    "        self.inceptionresnetC1 = block_C(1792,192)\n",
    "        self.inceptionresnetC2 = block_C(1792,192)\n",
    "        self.inceptionresnetC3 = block_C(1792,192)\n",
    "        self.inceptionresnetC4 = block_C(1792,192)\n",
    "        self.inceptionresnetC5 = block_C(1792,192)\n",
    "\n",
    "        self.avgpool = nn.AvgPool2d(7,1)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1792,1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024,num_classes)\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        x = self.inceptionresnetA1(x)\n",
    "        x = self.inceptionresnetA2(x)\n",
    "        x = self.inceptionresnetA3(x)\n",
    "        x = self.inceptionresnetA4(x)\n",
    "        x = self.inceptionresnetA5(x)\n",
    "        \n",
    "        x = self.reductiona(x)\n",
    "\n",
    "        x = self.inceptionresnetB1(x)\n",
    "        x = self.inceptionresnetB2(x)\n",
    "        x = self.inceptionresnetB3(x)\n",
    "        x = self.inceptionresnetB4(x)\n",
    "        x = self.inceptionresnetB5(x)\n",
    "        x = self.inceptionresnetB6(x)\n",
    "        x = self.inceptionresnetB7(x)\n",
    "        x = self.inceptionresnetB8(x)\n",
    "        x = self.inceptionresnetB9(x)\n",
    "        x = self.inceptionresnetB10(x)\n",
    "\n",
    "        x = self.reductionb(x)\n",
    "\n",
    "        x = self.inceptionresnetC1(x)\n",
    "        x = self.inceptionresnetC2(x)\n",
    "        x = self.inceptionresnetC3(x)\n",
    "        x = self.inceptionresnetC4(x)\n",
    "        x = self.inceptionresnetC5(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d1c186",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xception model\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class SeparableConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, bias=False):\n",
    "        super(SeparableConv2d, self).__init__()\n",
    "        self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size=kernel_size, \n",
    "                               groups=in_channels, bias=bias, padding=1)\n",
    "        self.pointwise = nn.Conv2d(in_channels, out_channels, \n",
    "                               kernel_size=1, bias=bias)\n",
    "    def forward(self, x):\n",
    "        out = self.depthwise(x)\n",
    "        out = self.pointwise(out)\n",
    "        return out\n",
    "\n",
    "class middleflow(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(middleflow, self).__init__()\n",
    "\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            SeparableConv2d(728,728, 3),\n",
    "            nn.BatchNorm2d(728),\n",
    "            nn.ReLU(),\n",
    "            SeparableConv2d(728,728, 3),\n",
    "            nn.BatchNorm2d(728),\n",
    "            nn.ReLU(),\n",
    "            SeparableConv2d(728,728, 3),\n",
    "            nn.BatchNorm2d(728),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        x =  self.layer(x)\n",
    "        x = x + identity\n",
    "        return x\n",
    "\n",
    "class exitflow(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(exitflow, self).__init__()\n",
    "\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            SeparableConv2d(728,728,3),\n",
    "            nn.BatchNorm2d(728),\n",
    "            nn.ReLU(),\n",
    "            SeparableConv2d(728,728,3),\n",
    "            nn.BatchNorm2d(728),\n",
    "            nn.MaxPool2d(3, 2,1)\n",
    "        )\n",
    "\n",
    "        self.conv1 = nn.Conv2d(728,728,1,2, 0)\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            SeparableConv2d(728,1536,3),\n",
    "            nn.BatchNorm2d(1536),\n",
    "            nn.ReLU(),\n",
    "            SeparableConv2d(1536,2048,3),\n",
    "            nn.BatchNorm2d(2048),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        con1 = self.conv1(x)\n",
    "        x = self.layer(x)\n",
    "        x = x + con1\n",
    "        x = self.layer2(x)\n",
    "        return x\n",
    "\n",
    "class Xception(nn.Module):\n",
    "    def __init__(self, in_channels=3, num_classes = 12) -> None:\n",
    "        super(Xception, self).__init__()\n",
    "        \n",
    "        # entry field - begins\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels=32, kernel_size=3, stride=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(64,128,1,2,0),\n",
    "            nn.BatchNorm2d(128))\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            SeparableConv2d(64,128, kernel_size=3),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            SeparableConv2d(128, 128, kernel_size=3),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(3, 2, 1)\n",
    "        )\n",
    "\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            SeparableConv2d(128, 256, kernel_size=3),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            SeparableConv2d(256,256, kernel_size=3),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.MaxPool2d(3, 2, 1)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(128,256,1,2, 0),\n",
    "            nn.BatchNorm2d(256))\n",
    "\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            SeparableConv2d(256, 728, kernel_size=3),\n",
    "            nn.BatchNorm2d(728),\n",
    "            nn.ReLU(),\n",
    "            SeparableConv2d(728,728, kernel_size=3),\n",
    "            nn.BatchNorm2d(728),\n",
    "            nn.MaxPool2d(3, 2, 1))\n",
    "        \n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(256,728,1,2, 0),\n",
    "            nn.BatchNorm2d(728))\n",
    "        # entry field - ends\n",
    "\n",
    "        self.middle = middleflow()\n",
    "        self.exitf = exitflow()\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(2048, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        con, layer = self.conv1(x), self.layer2(x)\n",
    "        x =  con + layer\n",
    "        con, layer =  self.conv2(x), self.layer3(x)\n",
    "        x = con + layer \n",
    "        con, layer = self.conv3(x), self.layer4(x)\n",
    "        x = con + layer\n",
    "        \n",
    "        x = self.middle(x)\n",
    "        x = self.middle(x)\n",
    "        x = self.middle(x)\n",
    "        x = self.middle(x)\n",
    "        x = self.middle(x)\n",
    "        x = self.middle(x)\n",
    "        x = self.middle(x)\n",
    "        x = self.middle(x)\n",
    "\n",
    "        x = self.exitf(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d3045b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import Workbook\n",
    "import openpyxl\n",
    "fname = \"SGD_momentum_last.xlsx\"\n",
    "\n",
    "#book = Workbook()\n",
    "#book.save(os.path.join(os.getcwd(), fname))\n",
    "#\"\"\"\n",
    "book = openpyxl.load_workbook(os.path.join(os.getcwd(), fname))\n",
    "sheet_name = 'alexnet'\n",
    "book.create_sheet(sheet_name)\n",
    "sheet = book[sheet_name]\n",
    "\n",
    "heads = [\"Epoch\", \"Training loss\", \"Training accuracy\", \"Validation loss\", \"Validation accuracy\",\"Epoch completed(sec)\", \"Pic number\", \"True labels\", \"Predictions\", \"Folder name\",\"Folder idx\"]\n",
    "\n",
    "for i in range(len(heads)): sheet.cell(1, i+1).value =  heads[i]\n",
    "#\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a968738",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Alexnet()\n",
    "num_epochs = 40\n",
    "learning_rate = 0.01\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay = 0.01) \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate, momentum = 0.9)\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "valid_acc = []\n",
    "train_acc = []\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    model.train()\n",
    "    \n",
    "    train_loss = 0\n",
    "    train_correct_pred = 0\n",
    "    train_total = 0\n",
    "    \n",
    "    valid_loss = 0\n",
    "    valid_correct_pred = 0\n",
    "    valid_total = 0\n",
    "    \n",
    "    since = time.time() \n",
    "    for i, (timages, tlabels) in enumerate(train_loader):\n",
    "        timages = timages.to(device)\n",
    "        tlabels = tlabels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        toutputs = model(timages)\n",
    "        _, tpred = torch.max(toutputs, 1)\n",
    "        train_total += tlabels.size(0)\n",
    "        train_correct_pred += (tpred==tlabels).sum().item()\n",
    "        \n",
    "        #print(f\"\\noutput: {tpred},\\tlabels: {tlabels}\")\n",
    "        tloss = criterion(toutputs,tlabels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        tloss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += tloss.item()*timages.size(0)\n",
    "    \n",
    "    t_acc = 100.0 * train_correct_pred/train_total\n",
    "    \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Epoch:{:d}/{:d} Training complete in {:.0f}m {:.0f}s'.format(epoch,num_epochs,time_elapsed // 60, time_elapsed % 60))\n",
    "    train_acc.append(t_acc)\n",
    "    \n",
    "    model.eval()\n",
    "    for i, (vimages, vlabels) in enumerate(test_loader):\n",
    "        vimages = vimages.to(device)\n",
    "        vlabels = vlabels.to(device)\n",
    "        voutputs = model(vimages)\n",
    "        _, vpred = torch.max(voutputs, 1)\n",
    "        valid_total += vlabels.size(0)\n",
    "        valid_correct_pred += (vpred==vlabels).sum().item()\n",
    "        #print(f\"{i}. output- >{outputs}, label {labels}\")\n",
    "        vloss = criterion(voutputs, vlabels)\n",
    "        valid_loss += vloss.item()*vimages.size(0)\n",
    "    \n",
    "    v_acc = 100.0 * valid_correct_pred/valid_total\n",
    "    valid_acc.append(v_acc)\n",
    "    \n",
    "    # calculate average losses\n",
    "    train_loss = train_loss/len(train_loader)\n",
    "    valid_loss = valid_loss/len(test_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss) \n",
    "    #print(f'train_acc ={train_correct_pred}, valid_acc ={valid_correct_pred}')   \n",
    "      #if (i-0)%30 == 0: print(f\"Epoch [{epoch+1}/{num_epochs}], Step = [{i+1}/{n_total_steps}], Loss = {loss.item():.4f}\")\n",
    "    \n",
    "    print(f'Epoch: {epoch}/{num_epochs} \\tTraining Loss: {train_loss:.3f}\\\n",
    "        \\tValidation Loss: {valid_loss:.3f} \\tTrain Acc: {t_acc:.3f} \\tValidation Acc: {v_acc:.3f}')\n",
    "    \n",
    "    sheet.cell(2+epoch-1, 1).value = epoch\n",
    "    sheet.cell(2+epoch-1, 2).value = train_loss\n",
    "    sheet.cell(2+epoch-1, 3).value = t_acc\n",
    "    sheet.cell(2+epoch-1, 4).value = valid_loss\n",
    "    sheet.cell(2+epoch-1, 5).value = v_acc\n",
    "    sheet.cell(2+epoch-1, 6).value = time_elapsed\n",
    "    \n",
    "print(\"Training Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec5cd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = []\n",
    "\n",
    "for idx in range(len(folders)): classes.append(folders[idx])\n",
    "\n",
    "truelabels = []\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    n_class_correct_pred = {classname: 0 for classname in classes}\n",
    "    n_class_total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "\n",
    "        _, predicted = torch.max(outputs,1)\n",
    "     \n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted==labels).sum().item()\n",
    "\n",
    "        for label, prediction in zip(labels, predicted):\n",
    "            truelabels.append(label.cpu().numpy())\n",
    "            predictions.append(prediction.cpu().numpy())\n",
    "            #print(f\"label->{label}------ prediction->{prediction}\")\n",
    "            #print(f\"labeltype->{type(label)}             pred type->{type(prediction)}\")\n",
    "            if label == prediction:\n",
    "                n_class_correct_pred[classes[label]] += 1\n",
    "            n_class_total_pred[classes[label]] += 1\n",
    "        \n",
    "    #test_loss_lst.append(test_loss/len(test_loader))\n",
    "\n",
    "    acc =  100.0 * n_correct/n_samples\n",
    "    print(f'Accuracy of the network: {acc:.5f} %\\n')\n",
    "\n",
    "    for classname, correct_count in n_class_correct_pred.items():\n",
    "        acc = 100.0 * float(correct_count)/n_class_total_pred[classname]\n",
    "        print(f'Accuracy of {classname:s}: {acc:.3f} %')\n",
    "print(n_class_correct_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7532a808",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(truelabels)):\n",
    "    sheet.cell(2+i, 7).value = i+1\n",
    "    sheet.cell(2+i, 8).value = int(truelabels[i])\n",
    "    sheet.cell(2+i, 9).value = int(predictions[i])\n",
    "\n",
    "for i in range(len(folders)):\n",
    "    sheet.cell(2+i, 10).value = folders[i]\n",
    "    sheet.cell(2+i, 11).value = i\n",
    "\n",
    "book.save(os.path.join(os.getcwd(), fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee4fca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "#import numpy as np\n",
    "\n",
    "\n",
    "cm = confusion_matrix(truelabels, predictions)\n",
    "\n",
    "df_cm = pd.DataFrame(cm, index = classes, columns = classes)\n",
    "plt.figure(figsize = (20,10))\n",
    "annot_kws={'fontsize':14,\n",
    "           'color':\"k\",\n",
    "           'verticalalignment':'center'}\n",
    "\n",
    "sns.heatmap(df_cm, annot = True, annot_kws = annot_kws, cmap ='Blues', vmin = 0, vmax = 100, linewidth = 0.2, linecolor = 'k')\n",
    "plt.xlabel('Predicted labels', fontsize = 24)\n",
    "plt.ylabel('True labels', fontsize = 24)\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(truelabels, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fcc7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1, figsize = (15,5))\n",
    "# Plot loss\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(train_losses, '-bx', label = 'Training loss')\n",
    "plt.plot(valid_losses, '-rx', label = 'Validation loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.title('Loss vs. No. of epochs')\n",
    "plt.grid()\n",
    "plt.legend(frameon = False)\n",
    "\n",
    "# Plot accuracy\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(train_acc, '-bx', label = 'Training acc')\n",
    "plt.plot(valid_acc, '-rx', label = 'Validation acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('acc')\n",
    "plt.title('Accuracy vs. No. of epochs')\n",
    "plt.legend(frameon = False)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf15e8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
